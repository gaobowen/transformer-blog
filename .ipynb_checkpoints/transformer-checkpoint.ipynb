{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b661ffb8-0c0d-47ef-b16f-08a951d1cad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget -O en-zh.tsv \"https://tatoeba.org/zh-cn/exports/download/48735/%E6%9C%89%E8%8B%B1%E8%AF%AD-%E4%B8%AD%E6%96%87%E6%99%AE%E9%80%9A%E8%AF%9D%E5%AF%B9%E5%BA%94%E5%8F%A5%20-%202024-06-11.tsv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca5673b-6fd7-44c7-a339-a4e8f7c7eb2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#将繁体转成简体\n",
    "!pip install zhconv\n",
    "from zhconv import convert\n",
    "\n",
    "def Q2B(uchar):\n",
    "  \"\"\"判断一个unicode是否是全角数字\"\"\"\n",
    "  if uchar >= u'\\uff10' and uchar <= u'\\uff19':\n",
    "    \"\"\"单个字符 全角转半角\"\"\"\n",
    "    inside_code = ord(uchar)\n",
    "    if inside_code == 0x3000:\n",
    "        inside_code = 0x0020\n",
    "    else:\n",
    "        inside_code -= 0xfee0\n",
    "    if inside_code < 0x0020 or inside_code > 0x7e: #转完之后不是半角字符返回原来的字符\n",
    "        return uchar\n",
    "    return chr(inside_code)\n",
    "  else:\n",
    "    return uchar\n",
    "\n",
    "def stringpartQ2B(ustring):\n",
    "  return \"\".join([Q2B(uchar) for uchar in ustring])\n",
    "\n",
    "\n",
    "def convertSimple(x):\n",
    "  return stringpartQ2B(convert(x.values[0], 'zh-cn'))\n",
    "\n",
    "\n",
    "all_data = pd.read_csv('en-zh.tsv',sep='\\t',on_bad_lines='skip',names=['NO.1','en','NO.2','zh'])\n",
    "\n",
    "zh_data = all_data.iloc[:,[3]].apply(convertSimple, axis=1).rename('zhs',inplace=True)\n",
    "\n",
    "all_data = pd.concat([all_data.iloc[:,[1]], zh_data], axis=1)\n",
    "\n",
    "all_data = all_data.applymap(lambda x: x.lower()) #英文全部转为小写\n",
    "\n",
    "print(type(all_data))\n",
    "print(type(all_data.values))\n",
    "all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf4a20a-f154-494a-ad29-aa5278827e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install nltk #英文分词\n",
    "!pip install jieba #中文分词\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.word_tokenize(\"today is june 18th and it is muiriel's birthday!\")\n",
    "\n",
    "import jieba\n",
    "jieba.lcut(\"今天是6月18号，也是muiriel的生日！\")\n",
    "\n",
    "en_list = all_data.iloc[:,[0]].applymap(lambda x: nltk.word_tokenize(x))\n",
    "zhs_list = all_data.iloc[:,[1]].applymap(lambda x: jieba.lcut(x))\n",
    "all_data = pd.concat([en_list,zhs_list],axis=1)\n",
    "\n",
    "# 添加两个特殊符号 <BOF> <EOF> 分别表示 句子的开始和结束\n",
    "all_data = all_data.applymap(lambda x: ['<BOF>']+ x +['<EOF>'])\n",
    "\n",
    "all_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "735f90cc-3180-4509-a3c1-22dd963211af",
   "metadata": {},
   "source": [
    "统计单词的频率，降序排列，用单词的下标作为单词的id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df6c7541-263f-417e-b324-6483a64c8ad5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('<PAD>', 0), ('<UNK>', 1), ('<BOF>', 2), ('<EOF>', 3), ('.', 4), ('the', 5), ('i', 6), ('to', 7), ('you', 8), ('is', 9), ('a', 10), ('?', 11), (',', 12), ('he', 13), (\"n't\", 14), ('in', 15), ('do', 16), ('of', 17), ('it', 18), (\"'s\", 19)]\n",
      "[(0, '<PAD>'), (1, '<UNK>'), (2, '<BOF>'), (3, '<EOF>'), (4, '.'), (5, 'the'), (6, 'i'), (7, 'to'), (8, 'you'), (9, 'is'), (10, 'a'), (11, '?'), (12, ','), (13, 'he'), (14, \"n't\"), (15, 'in'), (16, 'do'), (17, 'of'), (18, 'it'), (19, \"'s\")]\n",
      "=========\n",
      "[('<PAD>', 0), ('<UNK>', 1), ('<BOF>', 2), ('<EOF>', 3), ('。', 4), ('我', 5), ('的', 6), ('了', 7), ('你', 8), ('他', 9), ('，', 10), ('？', 11), ('是', 12), ('在', 13), ('她', 14), ('汤姆', 15), ('吗', 16), ('我们', 17), ('不', 18), ('很', 19)]\n",
      "[(0, '<PAD>'), (1, '<UNK>'), (2, '<BOF>'), (3, '<EOF>'), (4, '。'), (5, '我'), (6, '的'), (7, '了'), (8, '你'), (9, '他'), (10, '，'), (11, '？'), (12, '是'), (13, '在'), (14, '她'), (15, '汤姆'), (16, '吗'), (17, '我们'), (18, '不'), (19, '很')]\n",
      "英文词典长度 14738\n",
      "中文词典长度 25706\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "#统计单词的频率\n",
    "en_table = Counter([])\n",
    "zhs_table = Counter([])\n",
    "\n",
    "for row in all_data.values:\n",
    "  en_table.update(row[0])\n",
    "  zhs_table.update(row[1])\n",
    "\n",
    "en_to_id = {\"<PAD>\": 0, \"<UNK>\": 1,} # UNK表示未知字符，PAD表示占位符\n",
    "zhs_to_id = {\"<PAD>\": 0, \"<UNK>\": 1}\n",
    "\n",
    "id_to_en = {0: '<PAD>', 1:'<UNK>'}\n",
    "id_to_zhs = {0: '<PAD>', 1:'<UNK>'}\n",
    "\n",
    "#用数组下标作为单词的id，因为 0: '<PAD>', 1:'<UNK>' 所以id从2开始\n",
    "for idx,ele in enumerate(en_table.most_common(50000), start=2):\n",
    "  en_to_id[ele[0]] = idx\n",
    "  id_to_en[idx] = ele[0]\n",
    "\n",
    "print(list(en_to_id.items())[:20])\n",
    "print(list(id_to_en.items())[:20])\n",
    "print(\"=========\")\n",
    "\n",
    "for idx,ele in enumerate(zhs_table.most_common(50000), start=2):\n",
    "  zhs_to_id[ele[0]] = idx\n",
    "  id_to_zhs[idx] = ele[0]\n",
    "\n",
    "print(list(zhs_to_id.items())[:20])\n",
    "print(list(id_to_zhs.items())[:20])\n",
    "\n",
    "en_id_len = len(list(en_to_id.items()))\n",
    "zhs_id_len = len(list(zhs_to_id.items()))\n",
    "print(\"=========\")\n",
    "print('英文词典长度', en_id_len)\n",
    "print('中文词典长度', zhs_id_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ba9447a-5e21-404b-b204-0693dc615314",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_303578/2962820686.py:2: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  all_en_id = all_data.iloc[:,[0]].applymap(lambda x: [en_to_id.get(word, 0) for word in x]) # PAD=0\n",
      "/tmp/ipykernel_303578/2962820686.py:3: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  all_zhs_id = all_data.iloc[:,[1]].applymap(lambda x: [zhs_to_id.get(word, 0) for word in x]) # PAD=0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>en</th>\n",
       "      <th>zhs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[2, 6, 24, 7, 50, 7, 337, 4, 3]</td>\n",
       "      <td>[2, 5, 160, 22, 244, 7, 4, 3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[2, 119, 9, 1703, 5554, 31, 18, 9, 2983, 19, 5...</td>\n",
       "      <td>[2, 76, 12, 1487, 377, 2541, 1027, 10, 48, 12,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[2, 2983, 9, 1287, 95, 4, 3]</td>\n",
       "      <td>[2, 3548, 66, 1537, 580, 7, 4, 3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[2, 5, 2172, 9, 135, 2983, 137, 4, 3]</td>\n",
       "      <td>[2, 2176, 12, 307, 3548, 307, 4, 3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[2, 6, 48, 38, 140, 211, 4, 3]</td>\n",
       "      <td>[2, 5, 253, 39, 28, 166, 4, 3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68673</th>\n",
       "      <td>[2, 6, 42, 147, 29, 1150, 21, 23, 167, 19, 932...</td>\n",
       "      <td>[2, 276, 445, 123, 25, 5, 1591, 6, 2871, 8913,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68674</th>\n",
       "      <td>[2, 8, 42, 202, 22, 111, 4, 3]</td>\n",
       "      <td>[2, 8, 51, 73, 9208, 4, 3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68675</th>\n",
       "      <td>[2, 8, 160, 202, 22, 111, 4, 3]</td>\n",
       "      <td>[2, 8, 51, 73, 9208, 4, 3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68676</th>\n",
       "      <td>[2, 26, 363, 64, 5, 799, 12, 75, 26, 66, 14, 5...</td>\n",
       "      <td>[2, 14, 118, 1508, 10, 565, 132, 70, 225, 4, 3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68677</th>\n",
       "      <td>[2, 70, 949, 42, 304, 94, 617, 89, 243, 1619, ...</td>\n",
       "      <td>[2, 26, 1367, 25703, 6, 94, 10, 60, 104, 53, 6...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>68678 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      en  \\\n",
       "0                        [2, 6, 24, 7, 50, 7, 337, 4, 3]   \n",
       "1      [2, 119, 9, 1703, 5554, 31, 18, 9, 2983, 19, 5...   \n",
       "2                           [2, 2983, 9, 1287, 95, 4, 3]   \n",
       "3                  [2, 5, 2172, 9, 135, 2983, 137, 4, 3]   \n",
       "4                         [2, 6, 48, 38, 140, 211, 4, 3]   \n",
       "...                                                  ...   \n",
       "68673  [2, 6, 42, 147, 29, 1150, 21, 23, 167, 19, 932...   \n",
       "68674                     [2, 8, 42, 202, 22, 111, 4, 3]   \n",
       "68675                    [2, 8, 160, 202, 22, 111, 4, 3]   \n",
       "68676  [2, 26, 363, 64, 5, 799, 12, 75, 26, 66, 14, 5...   \n",
       "68677  [2, 70, 949, 42, 304, 94, 617, 89, 243, 1619, ...   \n",
       "\n",
       "                                                     zhs  \n",
       "0                          [2, 5, 160, 22, 244, 7, 4, 3]  \n",
       "1      [2, 76, 12, 1487, 377, 2541, 1027, 10, 48, 12,...  \n",
       "2                      [2, 3548, 66, 1537, 580, 7, 4, 3]  \n",
       "3                    [2, 2176, 12, 307, 3548, 307, 4, 3]  \n",
       "4                         [2, 5, 253, 39, 28, 166, 4, 3]  \n",
       "...                                                  ...  \n",
       "68673  [2, 276, 445, 123, 25, 5, 1591, 6, 2871, 8913,...  \n",
       "68674                         [2, 8, 51, 73, 9208, 4, 3]  \n",
       "68675                         [2, 8, 51, 73, 9208, 4, 3]  \n",
       "68676    [2, 14, 118, 1508, 10, 565, 132, 70, 225, 4, 3]  \n",
       "68677  [2, 26, 1367, 25703, 6, 94, 10, 60, 104, 53, 6...  \n",
       "\n",
       "[68678 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 把翻译数据全部转成id的表示形式\n",
    "all_en_id = all_data.iloc[:,[0]].applymap(lambda x: [en_to_id.get(word, en_to_id['<UNK>']) for word in x]) \n",
    "all_zhs_id = all_data.iloc[:,[1]].applymap(lambda x: [zhs_to_id.get(word, zhs_to_id['<UNK>']) for word in x]) \n",
    "all_data = pd.concat([all_en_id, all_zhs_id], axis=1)\n",
    "all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf502934-0b4d-48a2-acbd-a61d51f5e3f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
